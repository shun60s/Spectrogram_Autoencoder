<!DOCTYPE HTML>
<!DOCTYPE html PUBLIC " -//W3C//DTD HTML 4.01 Frameset//EN">
<HTML lang="en">
<HEAD><META content="IE=11.0000" http-equiv="X-UA-Compatible">
     
<META charset="UTF-8">     
<META name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.3.0 --> 
<TITLE>A practice of making mel spectrogram, CNN autoencode 
pre-training, and classifier by deep learning</TITLE> 
<META name="description" content="A practice of making mel spectrogram, CNN autoencode pre-training, and classifier by deep learning"> 
<META content="A practice of making mel spectrogram, CNN autoencode pre-training, and classifier by deep learning" 
property="og:description"> <LINK href="https://shun60s.github.io/spectrum/" rel="canonical"> 
<META content="https://shun60s.github.io/spectrum/" property="og:url"> 




 <LINK href="style.css" rel="stylesheet"> 
  
<META name="GENERATOR" content="MSHTML 11.00.10570.1001"></HEAD>   
<BODY>
<DIV class="container-lg px-3 my-5 markdown-body">
<H1 id="spectrum">mel spectrogram, autoencoder</H1>
<H2 id="abstract">Abstract</H2>
<P>A practice of making mel spectrogram, CNN autoencode pre-training, and 
classifier by deep learning Chainer</P>
<P><A href="https://github.com/shun60s/spectrum">github repository</A></P>
<H2 id="usage">Usage</H2>
<H3 id="1making-mel-spectrogram">1.making mel spectrogram</H3>
<P>Download the english number 0-9 speech data,  <A href="http://pannous.net/files/spoken_numbers_wav.tar">http://pannous.net/files/spoken_numbers_wav.tar</A><BR>
(See Description of Data in <A href="https://github.com/AKBoles/Deep-Learning-Speech-Recognition/blob/master/Pannous-Walkthrough.md">https://github.com/AKBoles/Deep-Learning-Speech-Recognition/blob/master/Pannous-Walkthrough.md</A> 
)<BR>and move wav files to wav directory. Steffi were removed due to it may 
soemthing wrong.</P>
<DIV class="highlighter-rouge">
<DIV class="highlight">
<PRE class="highlight"><CODE>python make_spectrogram.py
</CODE></PRE></DIV></DIV>
<P>Mel scale of FFT size, shift size, bands number, max frequency and min 
frequecny are adjustable as class GetSpecgram init<BR>Some input wav file of 
slow utterance (xxx40 &lt;=) or fast utterance (xxx260 &gt;=)  were rejected<BR>
spectrogram.zip is an example of output spectrogram directory.<BR><IMG alt="sample" 
src="mel-spectrogram-samples-of-number_0.png"></P>
<H3 id="2making-dataset">2.making DataSet</H3>
<P>Data set of 2D gray scale image and its label for classifier and 
autoencoder</P>
<DIV class="highlighter-rouge">
<DIV class="highlight">
<PRE class="highlight"><CODE>python make_dataset.py
</CODE></PRE></DIV></DIV>
<H3 id="3classifier-by-deep-learning-framework-chainer">3.classifier by deep 
learning framework Chainer</H3>
<P>2 CNN layers + FC  model</P>
<DIV class="highlighter-rouge">
<DIV class="highlight">
<PRE class="highlight"><CODE>python cnn_classifier1-2cnn.py
</CODE></PRE></DIV></DIV>
<P>3 CNN layers + FC  model</P>
<DIV class="highlighter-rouge">
<DIV class="highlight">
<PRE class="highlight"><CODE>python cnn_classifier1-3cnn.py
</CODE></PRE></DIV></DIV>
<P><IMG alt="sample" src="loss-accuracy_comparisonpng.png"><BR> 2 
CNN layers + FC is better performance than 3 CNN layers.</P>
<H3 id="4cnn-autoencoder-by-deep-learning-framework-chainer">4.CNN-Autoencoder 
by deep learning framework Chainer</H3>
<P>Customized chainer extensions of Updater, Evaluator, and plot_figure are 
used.<BR>input-&gt;encoder-&gt;decoder-&gt;output</P>
<DIV class="highlighter-rouge">
<DIV class="highlight">
<PRE class="highlight"><CODE>python cnn_autoencoder1.py
</CODE></PRE></DIV></DIV>
<P><IMG alt="sample" src="inout-comparison_autoencoder1-epoch10.png"></P>
<P>input&gt;encoder(fixed)-&gt;encoder-&gt;decoder&gt;decoder(fxied)-&gt;output<BR>
2nd layer of autoencoder training</P>
<DIV class="highlighter-rouge">
<DIV class="highlight">
<PRE class="highlight"><CODE>python cnn_autoencoder2.py
</CODE></PRE></DIV></DIV>
<P><IMG alt="sample" src="inout-comparison_autoencoder2-epoch10.png"></P>
<P>input&gt;encoder(fixed)-&gt;encoder(fixed)&gt;encoder-&gt;decoder-&gt;decoder(fixed)-&gt;decoder(fixed)&gt;output<BR>
3rd layer of autoencoder training</P>
<DIV class="highlighter-rouge">
<DIV class="highlight">
<PRE class="highlight"><CODE>python cnn_autoencoder3.py
</CODE></PRE></DIV></DIV>
<P><IMG alt="sample" src="inout-comparison_autoencoder3-epoch10.png"></P>
<H3 id="5classifier-with-pre-train">5.classifier with pre-train</H3>
<P>load autoencoder trained result, set as initial Weight and bias of CNN, and 
start training of classifier</P>
<DIV class="highlighter-rouge">
<DIV class="highlight">
<PRE class="highlight"><CODE>python cnn_classifier2-3cnn.py
</CODE></PRE></DIV></DIV>
<P><IMG alt="Comparison" src="loss-accuracy_comparisonpng_pre-train.png"><BR>
Pre-train method rises up faster, but, final performance may depends on layers 
structure.</P>
<H2 id="license">License</H2>
<P>Regarding to melbank.py, follow the license wrtten in the contents.</P>
<H2 id="references">References</H2>
<UL>
  <LI><A href="https://github.com/AKBoles/Deep-Learning-Speech-Recognition/blob/master/Pannous-Walkthrough.md">wav 
  of Pannous, Description</A></LI>
  <LI><A href="https://qiita.com/tommyfms2/items/c3fa0cb258c17468cb30">chainer 
  dataset</A></LI>
  <LI><A href="https://qiita.com/nyk510/items/bb49e1ab8770f6bfb7d1">chainer deep 
  autoencoder</A></LI>
  <LI><A href="http://mizti.hatenablog.com/entry/2017/10/24/011003">chainer 
  extension Evaluator</A></LI>
  <LI><A href="https://qiita.com/ysasaki6023/items/3040fe3896fe1ed844c3">chainer 
  extension DelGradient</A></LI>
  <LI><A href="https://qiita.com/crcrpar/items/ea05aadeb15aff817546">chainer 
  extension Updater</A></LI></UL>
<H2 id="disclaimer">Disclaimer</H2>
<P>THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR 
IMPLIED,  INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, 
FITNESS  FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL  THE 
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER 
LIABILITY,  WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, 
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE 
SOFTWARE.</P></DIV>
   </BODY></HTML>
